apiVersion: v1
kind: Secret
metadata:
  name: llm-credentials
  namespace: quantumlayer
type: Opaque
stringData:
  # Azure OpenAI - REPLACE WITH YOUR ACTUAL VALUES
  AZURE_OPENAI_KEY: "${AZURE_OPENAI_KEY}"
  AZURE_OPENAI_ENDPOINT: "${AZURE_OPENAI_ENDPOINT}"
  AZURE_OPENAI_DEPLOYMENT: "${AZURE_OPENAI_DEPLOYMENT}"
  AZURE_OPENAI_API_VERSION: "2024-02-01"
  AZURE_OPENAI_EMBEDDING_DEPLOYMENT: "${AZURE_OPENAI_EMBEDDING_DEPLOYMENT}"
  
  # AWS Bedrock - REPLACE WITH YOUR ACTUAL VALUES
  AWS_ACCESS_KEY_ID: "${AWS_ACCESS_KEY_ID}"
  AWS_SECRET_ACCESS_KEY: "${AWS_SECRET_ACCESS_KEY}"
  AWS_BEDROCK_REGION: "${AWS_BEDROCK_REGION:-us-east-1}"
  AWS_BEDROCK_MODEL: "${AWS_BEDROCK_MODEL:-anthropic.claude-3-haiku-20240307}"
  AWS_BEDROCK_EMBEDDING_MODEL: "${AWS_BEDROCK_EMBEDDING_MODEL:-amazon.titan-embed-text-v1}"
  
  # OpenAI - REPLACE WITH YOUR ACTUAL VALUES
  OPENAI_API_KEY: "${OPENAI_API_KEY}"
  OPENAI_ORG_ID: "${OPENAI_ORG_ID}"
  OPENAI_MODEL: "${OPENAI_MODEL:-gpt-4-turbo-preview}"
  
  # Anthropic - REPLACE WITH YOUR ACTUAL VALUES
  ANTHROPIC_API_KEY: "${ANTHROPIC_API_KEY}"
  ANTHROPIC_MODEL: "${ANTHROPIC_MODEL:-claude-3-opus-20240229}"
  
  # Groq - REPLACE WITH YOUR ACTUAL VALUES
  GROQ_API_KEY: "${GROQ_API_KEY}"
  GROQ_MODEL: "${GROQ_MODEL:-mixtral-8x7b-32768}"
  
  # Clerk Auth (if using) - REPLACE WITH YOUR ACTUAL VALUES
  CLERK_PUBLISHABLE_KEY: "${CLERK_PUBLISHABLE_KEY}"
  CLERK_SECRET_KEY: "${CLERK_SECRET_KEY}"

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: llm-router-config
  namespace: quantumlayer
data:
  PRIMARY_PROVIDER: "azure"
  FALLBACK_PROVIDERS: "groq,openai,anthropic,bedrock"
  ENABLED_PROVIDERS: "azure,groq,openai,anthropic,bedrock"
  REQUEST_TIMEOUT: "30s"
  MAX_RETRIES: "3"
  
  config.yaml: |
    server:
      port: 8080
      metrics_port: 9090
      health_port: 8081
      request_timeout: 30s
      shutdown_timeout: 10s
      
    providers:
      azure:
        enabled: true
        priority: 1
        timeout: 30s
        rateLimit: 100
        burstLimit: 200
        circuitBreaker:
          maxRequests: 3
          interval: 10s
          timeout: 60s
          failureRatio: 0.6
        retry:
          maxAttempts: 3
          initialInterval: 1s
          maxInterval: 10s
          multiplier: 2
          
      openai:
        enabled: true
        priority: 2
        endpoint: https://api.openai.com/v1
        timeout: 30s
        rateLimit: 50
        burstLimit: 100
        models:
          - gpt-4-turbo-preview
          - gpt-4
          - gpt-3.5-turbo
          
      anthropic:
        enabled: true
        priority: 3
        endpoint: https://api.anthropic.com
        timeout: 30s
        rateLimit: 30
        burstLimit: 60
        models:
          - claude-3-opus-20240229
          - claude-3-sonnet-20240229
          - claude-3-haiku-20240307
          
      groq:
        enabled: true
        priority: 4
        endpoint: https://api.groq.com/openai/v1
        timeout: 20s
        rateLimit: 30
        burstLimit: 50
        models:
          - mixtral-8x7b-32768
          - llama3-70b-8192
          - llama3-8b-8192
          
      bedrock:
        enabled: true
        priority: 5
        timeout: 30s
        rateLimit: 50
        burstLimit: 100
        models:
          - anthropic.claude-3-opus-20240229
          - anthropic.claude-3-sonnet-20240229
          - anthropic.claude-3-haiku-20240307
          - amazon.titan-text-express-v1
          
    routing:
      strategy: "priority-with-fallback"  # priority-with-fallback, round-robin, least-latency, cost-optimized
      healthCheck:
        enabled: true
        interval: 60s
        timeout: 10s
      fallback:
        enabled: true
        maxAttempts: 3
      
    codeGeneration:
      defaultMaxTokens: 2000
      defaultTemperature: 0.7
      validation:
        minLength: 30
        maxLength: 50000
        requireCodePatterns: true
        rejectConversational: true
      systemPrompts:
        default: |
          You are an expert software engineer and code generator.
          Generate production-ready, well-structured code following best practices.
          IMPORTANT: Return ONLY code without any explanations, markdown formatting, or conversational text.
          Do not include code block markers (```) or language tags.
          Generate pure, executable code only.
        enhanced: |
          You are an enterprise code generation system.
          Requirements:
          - Generate complete, production-ready code
          - Include all necessary imports and dependencies
          - Follow language-specific best practices and idioms
          - Implement proper error handling
          - Use meaningful variable and function names
          - Add minimal but essential comments for complex logic
          - Ensure code is secure and performant
          OUTPUT: Pure code only, no explanations or formatting.
          
    cache:
      enabled: true
      backend: "redis"
      ttl: 3600
      maxSize: 1000
      keyPrefix: "llm:cache:"
      
    security:
      apiKeyHeader: "X-API-Key"
      enableRateLimiting: true
      enableIPWhitelist: false
      ipWhitelist: []
      maxRequestSize: "10MB"
      
    observability:
      metrics:
        enabled: true
        prometheusPath: "/metrics"
      tracing:
        enabled: true
        jaegerEndpoint: "jaeger-collector.istio-system.svc.cluster.local:14268"
        samplingRate: 0.1
      logging:
        level: "info"
        format: "json"
        output: "stdout"
        
    performance:
      connectionPool:
        maxIdleConns: 100
        maxIdleConnsPerHost: 10
        idleConnTimeout: 90s
      compression:
        enabled: true
        level: 5